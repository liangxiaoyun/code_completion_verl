algorithm:
    adv_estimator: grpo
data:
    train_files: /data_train/liangxiaoyun/datas/completion_sft_datas/train_data_merge_user_distillation/250530_250630_completion_v1_sp_training_0731_deduplication_0.75_5_deduplicated_001_less_8000_filter0819_cursor_type_output_length_language_balance_sample_10000_none_2000_serious_badcase_2434.parquet
    val_files: /data_train/liangxiaoyun/datas/completion_sft_datas/train_data_merge_user_distillation/test_python_output.parquet
    shuffle: True
    train_batch_size: 1024
    max_prompt_length: 8000
    max_response_length: 256
    filter_overlong_prompts: True
    truncation: 'error'
actor_rollout_ref:
    model:
        path: /data_fast/jiaruiyu/workstation/user_data_analysis/LLM_post_training/output/250530_250630_completion_v1_sp_training_0731_deduplication_0.75_5_50k_user_50k_github_from_v4.0
        use_remove_padding: True
        enable_gradient_checkpointing: True
    actor:
        optim.lr: 1e-6
        use_dynamic_bsz: True
        optim.lr_warmup_steps: 40
        ppo_mini_batch_size: 4096
        ppo_micro_batch_size_per_gpu: 256
        fsdp_config.param_offload: True
        fsdp_config.optimizer_offload: True
        use_kl_loss: True
        kl_loss_coef: 0.001
        kl_loss_type: low_var_kl
        entropy_coeff: 0
    rollout:
        log_prob_micro_batch_size_per_gpu: 256
        tensor_model_parallel_size: 1
        name: vllm
        gpu_memory_utilization: 0.6
        max_num_batched_tokens: 16384
        n: 5
    ref:
        log_prob_micro_batch_size_per_gpu: 256
        fsdp_config.param_offload: True
    algorithm:
        use_kl_in_reward: False
trainer:
    critic_warmup: 0
    project_name: 'code-completion-grpo-project'
    experiment_name: 'grpo-v8.6.19_250811_multi_node'
    n_gpus_per_node: 8
    nnodes: 1
    save_freq: 14
    test_freq: 14
    logger: ['console','wandb','tensorboard']
    default_local_dir: /data_large/liangxiaoyun/model_output/grpo-v8.6.19_250811_multi_node
    total_epochs: 10
custom_reward_function:
    path: /data_train/liangxiaoyun/projects/verl/verl/utils/reward_score/code_completion_badcase_empty.py